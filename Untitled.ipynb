{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36757bed-80a3-4c62-a5fa-b923059fb320",
   "metadata": {
    "endofcell": "--"
   },
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     formats: ipynb,py:light\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.17.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# +\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import logging\n",
    "import joblib\n",
    "from prometheus_client import start_http_server, Gauge\n",
    "import time\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras\n",
    "import mlflow.pytorch\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 1. Chargement des données\n",
    "df = pd.read_csv(\"data/spam.csv\", encoding=\"ISO-8859-1\")\n",
    "df = df.rename(columns={df.columns[0]: \"label\", df.columns[1]: \"message\"})\n",
    "\n",
    "# 2. Conversion des labels (ham = 0, spam = 1)\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# 3. Nettoyage\n",
    "df.dropna(subset=['message'], inplace=True)\n",
    "\n",
    "# 4. Features & target\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "# 5. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Filtrage\n",
    "X_train = X_train[X_train.str.len() > 2]\n",
    "y_train = y_train[X_train.index]\n",
    "X_test = X_test[X_test.str.len() > 2]\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"Hate Speech Detection spam/ham\")\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def log_evaluation(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(model, name):\n",
    "        logging.info(f\"🚀 Début de l'évaluation du modèle {name}\")\n",
    "        result = func(model, name)\n",
    "        logging.info(f\"✅ Fin de l'évaluation du modèle {name} avec précision {result:.4f}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class TextClassifier(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, X, y): pass\n",
    "    @abstractmethod\n",
    "    def predict(self, X): pass\n",
    "\n",
    "class LogisticTextClassifier(TextClassifier):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X_vec = self.vectorizer.fit_transform(X)\n",
    "        self.model.fit(X_vec, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_vec = self.vectorizer.transform(X)\n",
    "        return self.model.predict(X_vec)\n",
    "\n",
    "class SVMTextClassifier(LogisticTextClassifier):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = LinearSVC()\n",
    "\n",
    "class NaiveBayesTextClassifier(LogisticTextClassifier):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = MultinomialNB()\n",
    "\n",
    "\n",
    "class LSTMTextClassifier(TextClassifier):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        X_seq = self.tokenizer.texts_to_sequences(X)\n",
    "        X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "        self.model = Sequential([\n",
    "            Embedding(len(self.tokenizer.word_index) + 1, 128),\n",
    "            LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model.fit(X_pad, y, epochs=3, batch_size=32)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_seq = self.tokenizer.texts_to_sequences(X)\n",
    "        X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "        return np.argmax(self.model.predict(X_pad), axis=1)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, name):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(name)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(f\"{name}_conf.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(model, X, y, name):\n",
    "    try:\n",
    "        if isinstance(model, LSTMTextClassifier):\n",
    "            X_seq = model.tokenizer.texts_to_sequences(X)\n",
    "            X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "            probs = model.model.predict(X_pad)\n",
    "            scores = probs[:, 1]  # Probabilité de la classe 1 (spam)\n",
    "        else:\n",
    "            if hasattr(model.model, 'decision_function'):\n",
    "                scores = model.model.decision_function(model.vectorizer.transform(X))\n",
    "            else:\n",
    "                scores = model.model.predict_proba(model.vectorizer.transform(X))[:, 1]\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y, scores)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc(fpr, tpr):.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve - {name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"{name}_roc.png\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"ROC non applicable pour {name}: {e}\")\n",
    "@log_evaluation\n",
    "@log_evaluation\n",
    "def evaluate_model(model, name):\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # 1. Log des paramètres (exemple simple ici)\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        \n",
    "        # 2. Entraînement du modèle\n",
    "        model.train(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # 3. Log de métriques\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "        # 4. Sauvegarde des visualisations\n",
    "        plot_confusion_matrix(y_test, y_pred, name)\n",
    "        plot_roc_curve(model, X_test, y_test, name)\n",
    "        mlflow.log_artifact(f\"{name}_conf.png\")\n",
    "        mlflow.log_artifact(f\"{name}_roc.png\")\n",
    "\n",
    "        # 5. Sauvegarde des modèles\n",
    "        model_dir = f\"models/{name.lower()}\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        if isinstance(model, LSTMTextClassifier):\n",
    "            model.model.save(f\"{model_dir}/model.h5\")\n",
    "            joblib.dump(model.tokenizer, f\"{model_dir}/tokenizer.pkl\")\n",
    "            mlflow.keras.log_model(model.model, artifact_path=\"model\")\n",
    "            mlflow.log_artifact(f\"{model_dir}/tokenizer.pkl\")\n",
    "        else:\n",
    "            joblib.dump(model.vectorizer, f\"{model_dir}/vectorizer.pkl\")\n",
    "            joblib.dump(model.model, f\"{model_dir}/model.pkl\")\n",
    "            mlflow.sklearn.log_model(model.model, artifact_path=\"model\")\n",
    "            mlflow.log_artifact(f\"{model_dir}/vectorizer.pkl\")\n",
    "\n",
    "        return acc\n",
    "\n",
    "def model_generator():\n",
    "    yield (\"Logistic\", LogisticTextClassifier())\n",
    "    yield (\"SVM\", SVMTextClassifier())\n",
    "    yield (\"NaiveBayes\", NaiveBayesTextClassifier())\n",
    "    yield (\"LSTM\", LSTMTextClassifier())\n",
    "class ModelIterator:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= len(self.models):\n",
    "            raise StopIteration\n",
    "        model = self.models[self.index]\n",
    "        self.index += 1\n",
    "        return model\n",
    "\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "accuracies = {}\n",
    "models = ModelIterator(list(model_generator()))\n",
    "for name, model in models:\n",
    "    acc = evaluate_model(model, name)\n",
    "    accuracies[name] = acc\n",
    "\n",
    "\n",
    "\n",
    "with open(\"cml-report.md\", \"w\") as f:\n",
    "    for name, acc in accuracies.items():\n",
    "        f.write(f\"## {name}\\n- Accuracy: {acc:.4f}\\n![{name} Confusion]({name}_conf.png)\\n\\n\")\n",
    "\n",
    "with open(\"metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Accuracy Scores:\\n\")\n",
    "    for name, acc in accuracies.items():\n",
    "        f.write(f\"{name}: {acc:.4f}\\n\")\n",
    "\n",
    "# Création de la métrique\n",
    "accuracy_gauge = Gauge('model_accuracy', 'Accuracy of the model', ['model'])\n",
    "\n",
    "# Fonction pour simuler un calcul de la précision et l'enregistrer\n",
    "def monitor_model_accuracy():\n",
    "    while True:\n",
    "        for model_name, accuracy in accuracies.items():\n",
    "            accuracy_gauge.labels(model=model_name).set(accuracy)\n",
    "        time.sleep(60)  # Met à jour les métriques toutes les 60 secondes\n",
    "\n",
    "# Démarrage du serveur HTTP pour exposer les métriques\n",
    "start_http_server(8000)  # Prometheus scrutera cette adresse\n",
    "monitor_model_accuracy()\n",
    "\n",
    "print(\"✅ Tous les modèles ont été entraînés et évalués avec succès.\")\n",
    "print(\"📄 Rapport Markdown généré : cml-report.md\")\n",
    "print(\"📁 Modèles sauvegardés dans le dossier 'models'\")\n",
    "print(\"📊 Fichier de métriques généré : metrics.txt\") \n",
    "# -\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# + endofcell=\"--\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf4ddc0-3424-4fac-9d95-0bec0e4a2497",
   "metadata": {
    "endofcell": "---",
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire courant : C:\\Users\\ILHAM\\projet-python-ilha\n"
     ]
    }
   ],
   "source": [
    "# # +\n",
    "import os\n",
    "\n",
    "# Répertoire courant du notebook\n",
    "print(\"Répertoire courant :\", os.getcwd())\n",
    "# -\n",
    "\n",
    "# --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b5e58-7781-43b1-8247-5db4fa01c3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7defa9-594a-41db-bd9f-c0637d741f4b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
