{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36757bed-80a3-4c62-a5fa-b923059fb320",
   "metadata": {
    "endofcell": "--"
   },
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     formats: ipynb,py:light\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.17.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# +\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import logging\n",
    "import joblib\n",
    "from prometheus_client import start_http_server, Gauge\n",
    "import time\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras\n",
    "import mlflow.pytorch\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 1. Chargement des donn√©es\n",
    "df = pd.read_csv(\"data/spam.csv\", encoding=\"ISO-8859-1\")\n",
    "df = df.rename(columns={df.columns[0]: \"label\", df.columns[1]: \"message\"})\n",
    "\n",
    "# 2. Conversion des labels (ham = 0, spam = 1)\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# 3. Nettoyage\n",
    "df.dropna(subset=['message'], inplace=True)\n",
    "\n",
    "# 4. Features & target\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "# 5. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Filtrage\n",
    "X_train = X_train[X_train.str.len() > 2]\n",
    "y_train = y_train[X_train.index]\n",
    "X_test = X_test[X_test.str.len() > 2]\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"Hate Speech Detection spam/ham\")\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def log_evaluation(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(model, name):\n",
    "        logging.info(f\"üöÄ D√©but de l'√©valuation du mod√®le {name}\")\n",
    "        result = func(model, name)\n",
    "        logging.info(f\"‚úÖ Fin de l'√©valuation du mod√®le {name} avec pr√©cision {result:.4f}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class TextClassifier(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, X, y): pass\n",
    "    @abstractmethod\n",
    "    def predict(self, X): pass\n",
    "\n",
    "class LogisticTextClassifier(TextClassifier):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X_vec = self.vectorizer.fit_transform(X)\n",
    "        self.model.fit(X_vec, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_vec = self.vectorizer.transform(X)\n",
    "        return self.model.predict(X_vec)\n",
    "\n",
    "class SVMTextClassifier(LogisticTextClassifier):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = LinearSVC()\n",
    "\n",
    "class NaiveBayesTextClassifier(LogisticTextClassifier):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = MultinomialNB()\n",
    "\n",
    "\n",
    "class LSTMTextClassifier(TextClassifier):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        X_seq = self.tokenizer.texts_to_sequences(X)\n",
    "        X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "        self.model = Sequential([\n",
    "            Embedding(len(self.tokenizer.word_index) + 1, 128),\n",
    "            LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model.fit(X_pad, y, epochs=3, batch_size=32)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_seq = self.tokenizer.texts_to_sequences(X)\n",
    "        X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "        return np.argmax(self.model.predict(X_pad), axis=1)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, name):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(name)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(f\"{name}_conf.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(model, X, y, name):\n",
    "    try:\n",
    "        if isinstance(model, LSTMTextClassifier):\n",
    "            X_seq = model.tokenizer.texts_to_sequences(X)\n",
    "            X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "            probs = model.model.predict(X_pad)\n",
    "            scores = probs[:, 1]  # Probabilit√© de la classe 1 (spam)\n",
    "        else:\n",
    "            if hasattr(model.model, 'decision_function'):\n",
    "                scores = model.model.decision_function(model.vectorizer.transform(X))\n",
    "            else:\n",
    "                scores = model.model.predict_proba(model.vectorizer.transform(X))[:, 1]\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y, scores)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc(fpr, tpr):.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve - {name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"{name}_roc.png\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"ROC non applicable pour {name}: {e}\")\n",
    "@log_evaluation\n",
    "@log_evaluation\n",
    "def evaluate_model(model, name):\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # 1. Log des param√®tres (exemple simple ici)\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        \n",
    "        # 2. Entra√Ænement du mod√®le\n",
    "        model.train(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # 3. Log de m√©triques\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "        # 4. Sauvegarde des visualisations\n",
    "        plot_confusion_matrix(y_test, y_pred, name)\n",
    "        plot_roc_curve(model, X_test, y_test, name)\n",
    "        mlflow.log_artifact(f\"{name}_conf.png\")\n",
    "        mlflow.log_artifact(f\"{name}_roc.png\")\n",
    "\n",
    "        # 5. Sauvegarde des mod√®les\n",
    "        model_dir = f\"models/{name.lower()}\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        if isinstance(model, LSTMTextClassifier):\n",
    "            model.model.save(f\"{model_dir}/model.h5\")\n",
    "            joblib.dump(model.tokenizer, f\"{model_dir}/tokenizer.pkl\")\n",
    "            mlflow.keras.log_model(model.model, artifact_path=\"model\")\n",
    "            mlflow.log_artifact(f\"{model_dir}/tokenizer.pkl\")\n",
    "        else:\n",
    "            joblib.dump(model.vectorizer, f\"{model_dir}/vectorizer.pkl\")\n",
    "            joblib.dump(model.model, f\"{model_dir}/model.pkl\")\n",
    "            mlflow.sklearn.log_model(model.model, artifact_path=\"model\")\n",
    "            mlflow.log_artifact(f\"{model_dir}/vectorizer.pkl\")\n",
    "\n",
    "        return acc\n",
    "\n",
    "def model_generator():\n",
    "    yield (\"Logistic\", LogisticTextClassifier())\n",
    "    yield (\"SVM\", SVMTextClassifier())\n",
    "    yield (\"NaiveBayes\", NaiveBayesTextClassifier())\n",
    "    yield (\"LSTM\", LSTMTextClassifier())\n",
    "class ModelIterator:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= len(self.models):\n",
    "            raise StopIteration\n",
    "        model = self.models[self.index]\n",
    "        self.index += 1\n",
    "        return model\n",
    "\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "accuracies = {}\n",
    "models = ModelIterator(list(model_generator()))\n",
    "for name, model in models:\n",
    "    acc = evaluate_model(model, name)\n",
    "    accuracies[name] = acc\n",
    "\n",
    "\n",
    "\n",
    "with open(\"cml-report.md\", \"w\") as f:\n",
    "    for name, acc in accuracies.items():\n",
    "        f.write(f\"## {name}\\n- Accuracy: {acc:.4f}\\n![{name} Confusion]({name}_conf.png)\\n\\n\")\n",
    "\n",
    "with open(\"metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Accuracy Scores:\\n\")\n",
    "    for name, acc in accuracies.items():\n",
    "        f.write(f\"{name}: {acc:.4f}\\n\")\n",
    "\n",
    "# Cr√©ation de la m√©trique\n",
    "accuracy_gauge = Gauge('model_accuracy', 'Accuracy of the model', ['model'])\n",
    "\n",
    "# Fonction pour simuler un calcul de la pr√©cision et l'enregistrer\n",
    "def monitor_model_accuracy():\n",
    "    while True:\n",
    "        for model_name, accuracy in accuracies.items():\n",
    "            accuracy_gauge.labels(model=model_name).set(accuracy)\n",
    "        time.sleep(60)  # Met √† jour les m√©triques toutes les 60 secondes\n",
    "\n",
    "# D√©marrage du serveur HTTP pour exposer les m√©triques\n",
    "start_http_server(8000)  # Prometheus scrutera cette adresse\n",
    "monitor_model_accuracy()\n",
    "\n",
    "print(\"‚úÖ Tous les mod√®les ont √©t√© entra√Æn√©s et √©valu√©s avec succ√®s.\")\n",
    "print(\"üìÑ Rapport Markdown g√©n√©r√© : cml-report.md\")\n",
    "print(\"üìÅ Mod√®les sauvegard√©s dans le dossier 'models'\")\n",
    "print(\"üìä Fichier de m√©triques g√©n√©r√© : metrics.txt\") \n",
    "# -\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# + endofcell=\"--\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf4ddc0-3424-4fac-9d95-0bec0e4a2497",
   "metadata": {
    "endofcell": "---",
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire courant : C:\\Users\\ILHAM\\projet-python-ilha\n"
     ]
    }
   ],
   "source": [
    "# # +\n",
    "import os\n",
    "\n",
    "# R√©pertoire courant du notebook\n",
    "print(\"R√©pertoire courant :\", os.getcwd())\n",
    "# -\n",
    "\n",
    "# --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b5e58-7781-43b1-8247-5db4fa01c3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7defa9-594a-41db-bd9f-c0637d741f4b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
